{
  "_comment_1": "========================================",
  "_comment_2": "MCP Server Configuration Example",
  "_comment_3": "========================================",
  "_comment_4": "",
  "_comment_5": "This file shows the configuration format for the Multi-Collection MCP Server.",
  "_comment_6": "To use: Copy this to markdown-notes-mcp-server/config.json and customize paths.",
  "_comment_7": "",
  "_comment_8": "Quick setup:",
  "_comment_9": "  1. cp config.json.example markdown-notes-mcp-server/config.json",
  "_comment_10": "  2. Edit markdown-notes-mcp-server/config.json with your absolute paths",
  "_comment_11": "  3. Ensure Ollama is running: ollama serve",
  "_comment_12": "  4. Ensure model is available: ollama pull mxbai-embed-large:latest",
  "_comment_13": "",

  "chromadb_path": "/absolute/path/to/search-markdown-notes/chromadb_data",
  "_chromadb_path_help": [
    "Absolute path to ChromaDB database directory",
    "MUST be absolute (no ~ or ../)",
    "Example macOS: /Users/yourname/search-markdown-notes/chromadb_data",
    "Example Linux: /home/yourname/search-markdown-notes/chromadb_data",
    "Example Windows: C:/Users/yourname/search-markdown-notes/chromadb_data",
    "Create collections with: cd bear-notes-cag-data-creator && python full_pipeline.py ..."
  ],

  "default_max_results": 3,
  "_default_max_results_help": [
    "Default number of search results to return per query",
    "Valid range: 1-100",
    "Recommended: 3-5 for most use cases",
    "AI agents can override this per-query"
  ],

  "embedding_model": "mxbai-embed-large:latest",
  "_embedding_model_help": [
    "Ollama model name for generating embeddings",
    "Format: model-name:tag",
    "Recommended: mxbai-embed-large:latest (1024 dimensions)",
    "IMPORTANT: Must match the model used to create embeddings in ChromaDB",
    "Install with: ollama pull mxbai-embed-large:latest"
  ]
}
